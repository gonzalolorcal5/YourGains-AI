# app/routes/chat.py
from fastapi import APIRouter, Header, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional
from sqlalchemy.orm import Session
import os
import logging
import json
from openai import OpenAI

from app.database import get_db
from app.models import Usuario

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

router = APIRouter()

class ChatRequestBody(BaseModel):
    message: str

class ChatResponse(BaseModel):
    answer: str
    chat_uses_free_restantes: Optional[int] = None

# Cliente OpenAI
api_key = os.getenv("OPENAI_API_KEY", "").strip()
client = None
if api_key:
    client = OpenAI(api_key=api_key)

def get_fitness_prompt():
    """Prompt base para el asistente de fitness"""
    return """Eres YourGains AI, un entrenador personal y nutricionista experto con m√°s de 10 a√±os de experiencia. 

Tu personalidad:
- Profesional pero cercano y motivador
- Basas tus respuestas en evidencia cient√≠fica
- Adaptas las recomendaciones al usuario espec√≠fico
- Siempre priorizas la seguridad y la progresi√≥n gradual
- Eres directo pero emp√°tico

√Åreas de expertise:
- Entrenamiento de fuerza y hipertrofia
- Nutrici√≥n deportiva y composici√≥n corporal
- Prevenci√≥n de lesiones
- Periodizaci√≥n del entrenamiento
- Suplementaci√≥n deportiva

Cuando respondas:
1. S√© espec√≠fico y pr√°ctico
2. Incluye el "por qu√©" detr√°s de tus recomendaciones
3. Adapta las respuestas al nivel del usuario
4. Si detectas algo peligroso, recomienda consultar un profesional
5. Mant√©n un tono motivador pero realista

Responde en espa√±ol y limita tus respuestas a 200 palabras m√°ximo para mantener la conversaci√≥n din√°mica."""

def call_openai_chat(message: str, user_email: str) -> str:
    """Llama a OpenAI con el contexto de fitness"""
    if not client:
        return "‚ö†Ô∏è Chat con IA temporalmente no disponible. Contacta con soporte."
    
    try:
        # Prompt del sistema + mensaje del usuario
        messages = [
            {
                "role": "system", 
                "content": get_fitness_prompt()
            },
            {
                "role": "user", 
                "content": f"Usuario: {user_email}\nPregunta: {message}"
            }
        ]
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # M√°s econ√≥mico que gpt-4
            messages=messages,
            temperature=0.7,
            max_tokens=300,
            presence_penalty=0.1,
            frequency_penalty=0.1
        )
        
        answer = response.choices[0].message.content.strip()
        
        # Log para debugging
        logger.info(f"Chat request from {user_email}: {message[:50]}...")
        logger.info(f"Chat response: {answer[:50]}...")
        
        return answer
        
    except Exception as e:
        logger.error(f"Error en OpenAI API: {str(e)}")
        return f"‚ùå Error al procesar tu pregunta. Int√©ntalo de nuevo en unos segundos."

def _demo_answer(msg: str) -> str:
    """Respuesta demo cuando no hay OpenAI configurado"""
    return f"""ü§ñ **Modo Demo - YourGains AI**

Pregunta recibida: "{msg}"

Esta es una respuesta de demostraci√≥n. Para activar el chat con IA real:

1. Configura tu OPENAI_API_KEY en las variables de entorno
2. La IA responder√° con consejos personalizados de entrenamiento y nutrici√≥n
3. Chat ilimitado para usuarios PREMIUM

*Tip: Para usuarios FREE quedan respuestas limitadas. ¬°Considera upgrade a PREMIUM!*"""

def _demo_stream_generator(msg: str):
    demo = _demo_answer(msg)
    for chunk in demo.split(" "):
        yield f"data: {chunk} \n\n"
    yield "event: done\n"
    yield "data: {}\n\n"

@router.post("/chat", response_model=ChatResponse)
def chat_endpoint(
    body: ChatRequestBody,
    db: Session = Depends(get_db),
    x_user_email: Optional[str] = Header(None, alias="X-User-Email"),
):
    """
    Chat con IA especializada en fitness.
    
    - FREE: 2 preguntas gratis
    - PREMIUM: Chat ilimitado
    """
    if not x_user_email:
        raise HTTPException(status_code=400, detail="Falta cabecera X-User-Email")

    # Validar formato de email b√°sico
    if "@" not in x_user_email or "." not in x_user_email:
        raise HTTPException(status_code=400, detail="Email inv√°lido")

    user = db.query(Usuario).filter(Usuario.email == x_user_email).first()
    if not user:
        raise HTTPException(status_code=404, detail="Usuario no encontrado")

    # Verificar estado premium
    plan_type = (user.plan_type or "FREE").upper()
    is_premium = plan_type == "PREMIUM" or bool(user.is_premium)

    # Control de l√≠mites para usuarios FREE
    if not is_premium and (user.chat_uses_free or 0) <= 0:
        raise HTTPException(
            status_code=402, 
            detail="Has agotado tus preguntas gratis. P√°sate a PREMIUM para chat ilimitado."
        )

    # Validar longitud del mensaje
    if len(body.message.strip()) < 3:
        raise HTTPException(status_code=400, detail="El mensaje debe tener al menos 3 caracteres")
    
    if len(body.message) > 500:
        raise HTTPException(status_code=400, detail="El mensaje es demasiado largo (m√°ximo 500 caracteres)")

    # Procesar con IA
    try:
        if api_key and client:
            answer = call_openai_chat(body.message, x_user_email)
        else:
            answer = _demo_answer(body.message)
        
        # Descontar uso si es FREE
        remaining = None
        if not is_premium:
            user.chat_uses_free = max(0, (user.chat_uses_free or 0) - 1)
            remaining = user.chat_uses_free
            db.commit()
            
        return ChatResponse(answer=answer, chat_uses_free_restantes=remaining)
        
    except Exception as e:
        logger.error(f"Error en chat endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail="Error interno del servidor")

# Endpoint adicional para obtener estado del chat
@router.get("/chat/status")
def chat_status(
    db: Session = Depends(get_db),
    x_user_email: Optional[str] = Header(None, alias="X-User-Email"),
):
    """Obtiene el estado actual del chat del usuario"""
    if not x_user_email:
        raise HTTPException(status_code=400, detail="Falta cabecera X-User-Email")
        
    user = db.query(Usuario).filter(Usuario.email == x_user_email).first()
    if not user:
        raise HTTPException(status_code=404, detail="Usuario no encontrado")
    
    is_premium = (user.plan_type == "PREMIUM") or bool(user.is_premium)
    
    return {
        "is_premium": is_premium,
        "chat_uses_free": user.chat_uses_free if not is_premium else None,
        "plan_type": user.plan_type,
        "openai_available": bool(api_key and client)
    }


@router.post("/chat/stream")
def chat_stream(
    body: ChatRequestBody,
    db: Session = Depends(get_db),
    x_user_email: Optional[str] = Header(None, alias="X-User-Email"),
):
    """Streaming SSE del chat para respuesta en tiempo real."""
    if not x_user_email:
        raise HTTPException(status_code=400, detail="Falta cabecera X-User-Email")

    if "@" not in x_user_email or "." not in x_user_email:
        raise HTTPException(status_code=400, detail="Email inv√°lido")

    user = db.query(Usuario).filter(Usuario.email == x_user_email).first()
    if not user:
        raise HTTPException(status_code=404, detail="Usuario no encontrado")

    plan_type = (user.plan_type or "FREE").upper()
    is_premium = plan_type == "PREMIUM" or bool(user.is_premium)

    if len(body.message.strip()) < 3:
        raise HTTPException(status_code=400, detail="El mensaje debe tener al menos 3 caracteres")
    if len(body.message) > 500:
        raise HTTPException(status_code=400, detail="El mensaje es demasiado largo (m√°ximo 500 caracteres)")

    # L√≠mite de FREE antes de comenzar a consumir recursos
    if not is_premium and (user.chat_uses_free or 0) <= 0:
        raise HTTPException(status_code=402, detail="Has agotado tus preguntas gratis. P√°sate a PREMIUM para chat ilimitado.")

    def event_generator():
        try:
            if not (api_key and client):
                # Stream de demo
                for line in _demo_stream_generator(body.message):
                    yield line
                # Ajuste de consumos para FREE
                remaining = None
                if not is_premium:
                    user.chat_uses_free = max(0, (user.chat_uses_free or 0) - 1)
                    remaining = user.chat_uses_free
                    db.commit()
                meta = {"chat_uses_free_restantes": remaining}
                yield f"event: meta\ndata: {json.dumps(meta, ensure_ascii=False)}\n\n"
                return

            # Construcci√≥n de mensajes para OpenAI
            messages = [
                {"role": "system", "content": get_fitness_prompt()},
                {"role": "user", "content": f"Usuario: {x_user_email}\nPregunta: {body.message}"},
            ]

            stream = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                temperature=0.7,
                max_tokens=300,
                stream=True,
            )

            # Emitir tokens seg√∫n llegan
            for chunk in stream:
                try:
                    delta = chunk.choices[0].delta
                    if not delta:
                        continue
                    text = getattr(delta, "content", None)
                    if not text:
                        continue
                    # Escape de nuevas l√≠neas conforme SSE
                    text = text.replace("\r", "").replace("\n", "\n")
                    yield f"data: {text}\n\n"
                except Exception:
                    continue

            # Fin del stream
            yield "event: done\n"
            yield "data: {}\n\n"

            # Descontar uso si es FREE
            remaining = None
            if not is_premium:
                user.chat_uses_free = max(0, (user.chat_uses_free or 0) - 1)
                remaining = user.chat_uses_free
                db.commit()

            meta = {"chat_uses_free_restantes": remaining}
            yield f"event: meta\ndata: {json.dumps(meta, ensure_ascii=False)}\n\n"

        except HTTPException as he:
            err = {"detail": he.detail}
            yield f"event: error\ndata: {json.dumps(err, ensure_ascii=False)}\n\n"
        except Exception as e:
            logger.error(f"Error en chat/stream: {str(e)}")
            err = {"detail": "Error interno del servidor"}
            yield f"event: error\ndata: {json.dumps(err, ensure_ascii=False)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")